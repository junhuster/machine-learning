{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory growth enabled for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'): True\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "sys.path.append('../../pytools')\n",
    "import d2l\n",
    "import os\n",
    "\n",
    "d2l.gpu_mem_init()\n",
    "tf.keras.config.disable_traceback_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class PositionWiseFFN(tf.keras.layers.Layer):\n",
    "    \"\"\"基于位置的前馈网络\"\"\"\n",
    "    def __init__(self, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.dense1 = tf.keras.layers.Dense(ffn_num_hiddens)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.dense2 = tf.keras.layers.Dense(ffn_num_outputs)\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 8)\n",
    "res = ffn(tf.ones((2, 3, 4)))\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer norm: tf.Tensor(\n",
      "[[-0.998006    0.9980061 ]\n",
      " [-0.9980061   0.99800587]], shape=(2, 2), dtype=float32) \n",
      "batch norm: tf.Tensor(\n",
      "[[-0.998006   -0.9980061 ]\n",
      " [ 0.9980061   0.99800587]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ln = tf.keras.layers.LayerNormalization()\n",
    "bn = tf.keras.layers.BatchNormalization()\n",
    "X = tf.constant([[1, 2], [2, 3]], dtype=tf.float32)\n",
    "print('layer norm:', ln(X), '\\nbatch norm:', bn(X, training=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class AddNorm(tf.keras.layers.Layer):\n",
    "    \"\"\"残差连接后进行层规范化\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self.ln = tf.keras.layers.LayerNormalization(normalized_shape)\n",
    "        #print(f\"nshape:{normalized_shape}\")\n",
    "\n",
    "    def call(self, X, Y, **kwargs):\n",
    "        return self.ln(self.dropout(Y, **kwargs) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:[[[ 0.23236084  0.20217764 -0.3336164   0.18651278]\n",
      "  [-0.05400848  0.5820098   0.5503016  -1.7578948 ]\n",
      "  [ 0.21130082  0.37275523 -0.3040274   0.6284828 ]]\n",
      "\n",
      " [[-0.9431824  -1.2125247  -0.90265286 -1.0118338 ]\n",
      "  [ 1.6236777  -0.481355    1.4131107  -0.6503676 ]\n",
      "  [-0.39259183  1.4331278   0.6805882   1.8753655 ]]]\n",
      "m:0.0430295355618, std:0.6207811832427979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.3048899 ,  0.25628436, -0.6065322 ,  0.23105842],\n",
       "        [-0.15626527,  0.8679475 ,  0.8168862 , -2.9001205 ],\n",
       "        [ 0.27097586,  0.53097415, -0.55888355,  0.9427854 ]],\n",
       "\n",
       "       [[-0.9346393 , -1.1715773 , -0.8989858 , -0.9950313 ],\n",
       "        [ 1.3234057 , -0.52837366,  1.1381718 , -0.6770526 ],\n",
       "        [-0.45028943,  1.1557806 ,  0.49377787,  1.5448134 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm([1, 2], 0.5)\n",
    "x = tf.random.normal((2,3,4))\n",
    "print(f\"x:{x}\")\n",
    "mean = np.mean(x[0])\n",
    "std = np.std(x[0])\n",
    "print(f\"m:{mean}, std:{std}\")\n",
    "add_norm(x, x, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"Transformer编码器块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_hiddens, num_heads, dropout, bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.attention = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens,\n",
    "                                                num_heads, dropout, bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def call(self, X, valid_lens, **kwargs):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens, **kwargs), **kwargs)\n",
    "        return self.addnorm2(Y, self.ffn(Y), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:1484: UserWarning: Layer 'multi_head_attention_27' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''got an unexpected keyword argument 'kwargs'''\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'multi_head_attention_27', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 24])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.ones((2, 100, 24))\n",
    "valid_lens = tf.constant([3, 2])\n",
    "norm_shape = [i for i in range(len(X.shape))][1:]\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, norm_shape, 48, 8, 0.5)\n",
    "encoder_blk(X, valid_lens, training=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(d2l.Encoder):\n",
    "    \"\"\"Transformer编码器\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_hiddens, num_heads,\n",
    "                 num_layers, dropout, bias=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = [EncoderBlock(\n",
    "            key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "            ffn_num_hiddens, num_heads, dropout, bias) for _ in range(\n",
    "            num_layers)]\n",
    "\n",
    "    def call(self, X, valid_lens, **kwargs):\n",
    "        # 因为位置编码值在-1和1之间，\n",
    "        # 因此嵌入值乘以嵌入维度的平方根进行缩放，\n",
    "        # 然后再与位置编码相加。\n",
    "        X = self.pos_encoding(self.embedding(X) * tf.math.sqrt(\n",
    "            tf.cast(self.num_hiddens, dtype=tf.float32)), **kwargs)\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens, **kwargs)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:1484: UserWarning: Layer 'multi_head_attention_28' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''got an unexpected keyword argument 'kwargs'''\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'multi_head_attention_28', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:1484: UserWarning: Layer 'multi_head_attention_29' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''got an unexpected keyword argument 'kwargs'''\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'multi_head_attention_29', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 24])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(200, 24, 24, 24, 24, [1, 2], 48, 8, 2, 0.5)\n",
    "encoder(tf.ones((2, 100)), valid_lens, training=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    \"\"\"解码器中第i个块\"\"\"\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_hiddens, num_heads, dropout, i, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = d2l.MultiHeadAttention(key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    ## TODO 原代码def call() 会报错，改成__call()__不报错, 原因待查\n",
    "    def __call__(self, X, state, **kwargs):\n",
    "        \n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # 训练阶段，输出序列的所有词元都在同一时间处理，\n",
    "        # 因此state[2][self.i]初始化为None。\n",
    "        # 预测阶段，输出序列是通过词元一个接着一个解码的，\n",
    "        # 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示\n",
    "        \n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = tf.concat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if kwargs['training']:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "           # dec_valid_lens的开头:(batch_size,num_steps),\n",
    "            # 其中每一行是[1,2,...,num_steps]\n",
    "            dec_valid_lens = tf.repeat(tf.reshape(tf.range(1, num_steps + 1),\n",
    "                                                 shape=(-1, num_steps)), repeats=batch_size, axis=0)\n",
    "\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # 自注意力\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens, **kwargs)\n",
    "        Y = self.addnorm1(X, X2, **kwargs)\n",
    "        # 编码器－解码器注意力。\n",
    "        # enc_outputs的开头:(batch_size,num_steps,num_hiddens)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens, **kwargs)\n",
    "        Z = self.addnorm2(Y, Y2, **kwargs)\n",
    "        return self.addnorm3(Z, self.ffn(Z), **kwargs), state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 100, 24])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [1, 2], 48, 8, 0.5, 0)\n",
    "X = tf.ones((2, 100, 24))\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state, training=False)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(d2l.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_hidens, num_heads, num_layers, dropout, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = [DecoderBlock(key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "                                  ffn_num_hiddens, num_heads, dropout, i) for i in range(num_layers)]\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "    ##TODO call-->__call()__\n",
    "    def __call__(self, X, state, **kwargs):\n",
    "        X = self.pos_encoding(self.embedding(X) * tf.math.sqrt(tf.cast(self.num_hiddens, dtype=tf.float32)), **kwargs)\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range(2)]  # 解码器中2个注意力层\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state, **kwargs)\n",
    "            # 解码器自注意力权重\n",
    "            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n",
    "            # “编码器－解码器”自注意力权重\n",
    "            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.031, 448.2 tokens/sec on <tensorflow.python.eager.context._EagerDeviceContext object at 0x7f384c4d0180>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, d2l.try_gpu()\n",
    "ffn_num_hiddens, num_heads = 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [2]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "    ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens, norm_shape,\n",
    "    ffn_num_hiddens, num_heads, num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "d2l.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va .,  bleu 0.000\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "he's calm . => il est calme .,  bleu 1.000\n",
      "i'm home . => je suis chez moi .,  bleu 1.000\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = d2l.predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, True)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {d2l.bleu(translation, fra, k=2):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
